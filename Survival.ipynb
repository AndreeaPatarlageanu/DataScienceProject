{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36c29cf-1bbb-418c-b6dd-f6cbd06269dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_survival_data(data: pd.DataFrame, observation_end=None):\n",
    "    \"\"\"\n",
    "    Prepare data for survival analysis.\n",
    "    \n",
    "    Args:\n",
    "        data: Event-level DataFrame\n",
    "        observation_end: Cutoff date for observation window\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame ready for survival modeling\n",
    "    \"\"\"\n",
    "    if observation_end is None:\n",
    "        observation_end = data['ts'].max()\n",
    "    else:\n",
    "        observation_end = pd.Timestamp(observation_end)\n",
    "    \n",
    "    # Convert timestamps\n",
    "    data['ts'] = pd.to_datetime(data['ts'])\n",
    "    data['registration'] = pd.to_datetime(data['registration'])\n",
    "    \n",
    "    # Create derived columns BEFORE aggregating\n",
    "    data['song_played'] = (data['page'] == 'NextSong').astype(int)\n",
    "    \n",
    "    # Calculate session length\n",
    "    data = data.sort_values(['userId', 'sessionId', 'ts'])\n",
    "    data['session_length'] = data.groupby(['userId', 'sessionId'])['ts'].transform(\n",
    "        lambda x: (x.max() - x.min()).total_seconds()\n",
    "    )\n",
    "    \n",
    "    # Identify churned users\n",
    "    churned_users = set(data[data['page'] == 'Cancellation Confirmation']['userId'].unique())\n",
    "    data['churned'] = data['userId'].isin(churned_users).astype(int)\n",
    "    \n",
    "    # Aggregate\n",
    "    user_df = data.groupby('userId').agg({\n",
    "        'gender': 'first',\n",
    "        'registration': 'first',\n",
    "        'level': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
    "        'sessionId': 'nunique',\n",
    "        'itemInSession': ['max', 'mean'],\n",
    "        'ts': ['min', 'max'],\n",
    "        'session_length': ['mean', 'std', 'max'],\n",
    "        'song_played': 'sum',\n",
    "        'artist': 'nunique',\n",
    "        'length': ['sum', 'mean'],\n",
    "        'churned': 'max'    \n",
    "    }).reset_index()\n",
    "    \n",
    "    user_df.columns = ['userId', 'gender', 'registration', 'level',\n",
    "                       'num_sessions', 'max_item_in_session', 'avg_item_in_session',\n",
    "                       'ts_min', 'ts_max', \n",
    "                       'avg_session_length_seconds', 'std_session_length', 'max_session_length',\n",
    "                       'num_songs_played', 'unique_artists', 'total_length', 'avg_song_length',\n",
    "                       'churned']\n",
    "    \n",
    "    # ENCODE CATEGORICAL VARIABLES\n",
    "    # Gender: convert to numeric (assuming 'M'=1, 'F'=0, or use label encoding)\n",
    "    gender_map = {'M': 1, 'F': 0}\n",
    "    user_df['gender'] = user_df['gender'].map(gender_map).fillna(0).astype(int)\n",
    "    \n",
    "    # Level: convert to numeric (assuming 'paid'=1, 'free'=0)\n",
    "    level_map = {'paid': 1, 'free': 0}\n",
    "    user_df['level'] = user_df['level'].map(level_map).fillna(0).astype(int)\n",
    "    \n",
    "    # Calculate duration\n",
    "    user_df['duration'] = (user_df['ts_max'] - user_df['registration']).dt.days\n",
    "    user_df['duration'] = user_df['duration'].clip(lower=1)\n",
    "    \n",
    "    # Event indicator\n",
    "    user_df['event'] = user_df['churned']\n",
    "    \n",
    "    # Temporal features\n",
    "    user_df['days_active'] = (pd.to_datetime(observation_end) - pd.to_datetime(user_df['ts_min'])).dt.days\n",
    "    user_df['membership_length'] = (pd.to_datetime(observation_end) - pd.to_datetime(user_df['registration'])).dt.days\n",
    "    user_df['days_since_last_activity'] = (pd.to_datetime(observation_end) - pd.to_datetime(user_df['ts_max'])).dt.days\n",
    "    \n",
    "    # Engagement features\n",
    "    user_df['songs_per_day'] = user_df['num_songs_played'] / (user_df['days_active'] + 1)\n",
    "    user_df['sessions_per_day'] = user_df['num_sessions'] / (user_df['days_active'] + 1)\n",
    "    user_df['songs_per_session'] = user_df['num_songs_played'] / (user_df['num_sessions'] + 1)\n",
    "    \n",
    "    # Diversity and behavior metrics\n",
    "    user_df['artist_diversity_ratio'] = user_df['unique_artists'] / (user_df['num_songs_played'] + 1)\n",
    "    user_df['avg_listening_time_per_day'] = user_df['total_length'] / (user_df['days_active'] + 1)\n",
    "    user_df['inactivity_ratio'] = user_df['days_since_last_activity'] / (user_df['membership_length'] + 1)\n",
    "    user_df['session_length_cv'] = user_df['std_session_length'] / (user_df['avg_session_length_seconds'] + 1)\n",
    "    \n",
    "    user_df = user_df.fillna(0)\n",
    "    \n",
    "    print(f\"Processed {len(user_df)} users\")\n",
    "    print(f\"Churn rate: {user_df['churned'].mean():.2%}\")\n",
    "    print(f\"Censored rate: {(1 - user_df['event']).mean():.2%}\")\n",
    "    print(f\"Median duration: {user_df['duration'].median()} days\")\n",
    "    \n",
    "    return user_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0f7c25-1325-42eb-b530-15bf2d25306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('Data/train.parquet')  # your event data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833c9121-a904-4639-b3cd-2fdc305e5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 19140 users\n",
      "Churn rate: 22.31%\n",
      "Censored rate: 77.69%\n",
      "Median duration: 1.0 days\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare training data\n",
    "train_survival = prepare_survival_data(train_data)\n",
    "\n",
    "# Select features for Cox model (drop datetime and redundant columns)\n",
    "feature_cols = [\n",
    "    'gender', 'level', 'num_sessions', 'max_item_in_session', 'avg_item_in_session',\n",
    "    'avg_session_length_seconds', 'std_session_length', 'max_session_length',\n",
    "    'num_songs_played', 'unique_artists', 'avg_song_length',\n",
    "    'songs_per_day', 'sessions_per_day', 'songs_per_session',\n",
    "    'artist_diversity_ratio', 'avg_listening_time_per_day',\n",
    "    'inactivity_ratio', 'session_length_cv', 'days_since_last_activity',\n",
    "    'duration', 'event'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63e49df-fe83-4be8-8615-e0f0e35510c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing low-variance columns: ['avg_session_length_seconds', 'std_session_length', 'max_session_length', 'inactivity_ratio', 'session_length_cv', 'days_since_last_activity']\n",
      "Iteration 1: norm_delta = 6.28e-02, step_size = 0.9500, log_lik = -41593.65349, newton_decrement = 1.50e+01, seconds_since_start = 0.0\n",
      "Iteration 2: norm_delta = 3.28e-03, step_size = 0.9500, log_lik = -41578.78565, newton_decrement = 3.05e-02, seconds_since_start = 0.0\n",
      "Iteration 3: norm_delta = 1.65e-04, step_size = 0.9500, log_lik = -41578.75526, newton_decrement = 7.77e-05, seconds_since_start = 0.0\n",
      "Iteration 4: norm_delta = 7.32e-09, step_size = 1.0000, log_lik = -41578.75518, newton_decrement = 1.66e-13, seconds_since_start = 0.0\n",
      "Convergence success after 4 iterations.\n",
      "\n",
      "Cox Model Summary:\n",
      "                                    coef  exp(coef)      se(coef)  \\\n",
      "covariate                                                           \n",
      "gender                      2.667034e-02   1.027029  2.547269e-02   \n",
      "level                       7.703518e-02   1.080080  3.020207e-02   \n",
      "num_sessions               -1.589288e-03   0.998412  1.853721e-03   \n",
      "max_item_in_session        -9.605531e-06   0.999990  1.050856e-04   \n",
      "avg_item_in_session         7.287558e-04   1.000729  3.541760e-04   \n",
      "num_songs_played           -1.408842e-08   1.000000  2.323895e-05   \n",
      "unique_artists             -6.690009e-06   0.999993  4.059236e-05   \n",
      "avg_song_length             8.366169e-05   1.000084  1.049337e-03   \n",
      "songs_per_day              -1.408842e-08   1.000000  2.323895e-05   \n",
      "sessions_per_day           -1.589288e-03   0.998412  1.853721e-03   \n",
      "songs_per_session           3.332419e-04   1.000333  4.901579e-04   \n",
      "artist_diversity_ratio      1.121710e-01   1.118704  1.668409e-01   \n",
      "avg_listening_time_per_day -8.606145e-10   1.000000  9.342731e-08   \n",
      "\n",
      "                            coef lower 95%  coef upper 95%  \\\n",
      "covariate                                                    \n",
      "gender                       -2.325521e-02    7.659588e-02   \n",
      "level                         1.784020e-02    1.362302e-01   \n",
      "num_sessions                 -5.222515e-03    2.043939e-03   \n",
      "max_item_in_session          -2.155694e-04    1.963584e-04   \n",
      "avg_item_in_session           3.458353e-05    1.422928e-03   \n",
      "num_songs_played             -4.556159e-05    4.553341e-05   \n",
      "unique_artists               -8.624958e-05    7.286956e-05   \n",
      "avg_song_length              -1.973002e-03    2.140325e-03   \n",
      "songs_per_day                -4.556159e-05    4.553341e-05   \n",
      "sessions_per_day             -5.222515e-03    2.043939e-03   \n",
      "songs_per_session            -6.274499e-04    1.293934e-03   \n",
      "artist_diversity_ratio       -2.148312e-01    4.391732e-01   \n",
      "avg_listening_time_per_day   -1.839748e-07    1.822535e-07   \n",
      "\n",
      "                            exp(coef) lower 95%  exp(coef) upper 95%  cmp to  \\\n",
      "covariate                                                                      \n",
      "gender                                 0.977013             1.079606     0.0   \n",
      "level                                  1.018000             1.145946     0.0   \n",
      "num_sessions                           0.994791             1.002046     0.0   \n",
      "max_item_in_session                    0.999784             1.000196     0.0   \n",
      "avg_item_in_session                    1.000035             1.001424     0.0   \n",
      "num_songs_played                       0.999954             1.000046     0.0   \n",
      "unique_artists                         0.999914             1.000073     0.0   \n",
      "avg_song_length                        0.998029             1.002143     0.0   \n",
      "songs_per_day                          0.999954             1.000046     0.0   \n",
      "sessions_per_day                       0.994791             1.002046     0.0   \n",
      "songs_per_session                      0.999373             1.001295     0.0   \n",
      "artist_diversity_ratio                 0.806678             1.551424     0.0   \n",
      "avg_listening_time_per_day             1.000000             1.000000     0.0   \n",
      "\n",
      "                                   z         p  -log2(p)  \n",
      "covariate                                                 \n",
      "gender                      1.047017  0.295092  1.760765  \n",
      "level                       2.550659  0.010752  6.539257  \n",
      "num_sessions               -0.857350  0.391251  1.353832  \n",
      "max_item_in_session        -0.091407  0.927169  0.109095  \n",
      "avg_item_in_session         2.057609  0.039628  4.657348  \n",
      "num_songs_played           -0.000606  0.999516  0.000698  \n",
      "unique_artists             -0.164810  0.869094  0.202416  \n",
      "avg_song_length             0.079728  0.936453  0.094721  \n",
      "songs_per_day              -0.000606  0.999516  0.000698  \n",
      "sessions_per_day           -0.857350  0.391251  1.353832  \n",
      "songs_per_session           0.679867  0.496589  1.009876  \n",
      "artist_diversity_ratio      0.672323  0.501378  0.996029  \n",
      "avg_listening_time_per_day -0.009212  0.992650  0.010643  \n",
      "\n",
      "Concordance Index: 0.535\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    'gender', 'level', 'num_sessions', 'max_item_in_session', 'avg_item_in_session',\n",
    "    'avg_session_length_seconds', 'std_session_length', 'max_session_length',\n",
    "    'num_songs_played', 'unique_artists', 'avg_song_length',\n",
    "    'songs_per_day', 'sessions_per_day', 'songs_per_session',\n",
    "    'artist_diversity_ratio', 'avg_listening_time_per_day',\n",
    "    'inactivity_ratio', 'session_length_cv', 'days_since_last_activity',\n",
    "    'duration', 'event'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "train_cox = train_survival[feature_cols].copy()\n",
    "\n",
    "# Additional check: remove any remaining low-variance columns\n",
    "variance = train_cox.drop(columns=['duration', 'event']).var()\n",
    "low_variance_cols = variance[variance < 0.01].index.tolist()\n",
    "if low_variance_cols:\n",
    "    print(f\"Removing low-variance columns: {low_variance_cols}\")\n",
    "    train_cox = train_cox.drop(columns=low_variance_cols)\n",
    "\n",
    "# Fit the model\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "cph = CoxPHFitter(penalizer=0.1)\n",
    "cph.fit(train_cox, duration_col='duration', event_col='event', \n",
    "         show_progress=True)\n",
    "\n",
    "print(\"\\nCox Model Summary:\")\n",
    "print(cph.summary)\n",
    "print(f\"\\nConcordance Index: {cph.concordance_index_:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9543453f-b5a7-42b0-a235-370ac305f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2904 users\n",
      "Churn rate: 0.00%\n",
      "Censored rate: 100.00%\n",
      "Median duration: 1.0 days\n",
      "\n",
      "Predicted churn rate: 50.00%\n",
      "Submission saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For test set predictions\n",
    "test_data = pd.read_parquet('Data/test.parquet')\n",
    "test_survival = prepare_survival_data(test_data)\n",
    "test_cox = test_survival[feature_cols].drop(columns=['duration', 'event'])\n",
    "\n",
    "# Get risk scores (higher = higher risk of churning)\n",
    "risk_scores = cph.predict_partial_hazard(test_cox)\n",
    "\n",
    "# Convert to binary predictions (top 50% = churn for balanced test set)\n",
    "threshold = np.percentile(risk_scores, 50)\n",
    "y_pred = (risk_scores >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nPredicted churn rate: {y_pred.mean():.2%}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_survival['userId'],\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('survival_submission.csv', index=False)\n",
    "print(\"Submission saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78dcd7-2f60-4f55-8b9b-37e9600bb76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Science",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
