{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be21dc6b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91707aa2",
   "metadata": {},
   "source": [
    "In this notebook, we apply Logistic Regression to our data and we try to predict 'churn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8dcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports will be here:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import import_and_transform\n",
    "from utils import evaluate_model\n",
    "from utils import aggregate, aggregate_features_improved, aggregate_features_improved2\n",
    "from utils import get_churned_users\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eee076",
   "metadata": {},
   "source": [
    "Based on the exploratory data analysis **EDA**, we will now modify our database accordingly. The EDA showed issues and necessary changed that require database modifications.\n",
    "\n",
    "We restructurate our database:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b204f2",
   "metadata": {},
   "source": [
    "Since in this competitions task we are asked to focus on the churn in a specific time window, we create a function which identifies who churned within a specified period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c4a47",
   "metadata": {},
   "source": [
    "Now, we are ready to load the train and test data and apply these modifications directly on our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbcd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = import_and_transform(\"Data/train.parquet\")\n",
    "\n",
    "# Prepare test data\n",
    "df_test = import_and_transform(\"Data/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab4245",
   "metadata": {},
   "source": [
    "We want to capture more temporal patterns. We want to \"teach\" the model to recognize churn patterns across different time periods. How do we do that?\n",
    "\n",
    "If we look at only one point in the time, we do not have enough examples to train the model. So instead of taking just one \"snapshot\", we take multiple snapshots at different times and we consider each one of them as individual prediction problems. \n",
    "\n",
    "Like this, we increase our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createing observation dates every 5 days\n",
    "# Create multiple training samples with sliding window\n",
    "training_dates = pd.date_range(\"2018-10-15\", \"2018-11-05\", freq=\"5D\")\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "# For each observ date, we create a separate training sample:\n",
    "for obs_date in training_dates:\n",
    "    # Filtering data up to the observation date\n",
    "    df_obs = df_train[df_train[\"ts\"] <= obs_date]\n",
    "    features = aggregate_features_improved(df_obs, obs_date)   # Better aggregate function.\n",
    "    # features = aggregate_features_improved2(df_obs, obs_date)  # Better function, but takes ages to run\n",
    "    \n",
    "    # Creating a 10 day window after the obervation date\n",
    "    # And we identify who churned in that period\n",
    "    window_end = obs_date + pd.Timedelta(days=10)\n",
    "    churned_users = get_churned_users(df_train, obs_date, window_end)\n",
    "\n",
    "    # 1 if they churned in the next 10 days, 0 otherwise\n",
    "    labels = pd.Series(\n",
    "        features.index.isin(churned_users).astype(int),\n",
    "        index=features.index,\n",
    "        name=\"churned\",\n",
    "    )\n",
    "\n",
    "    X_train_list.append(features)\n",
    "    y_train_list.append(labels)\n",
    "\n",
    "    print(\n",
    "        f\"Date of the observation: {obs_date.date()}, with {len(features)} users, and a {labels.mean():.2%} churn rate\"\n",
    "    )\n",
    "\n",
    "# We combine all observation windows:\n",
    "X_train_combined = pd.concat(X_train_list)\n",
    "y_train_combined = pd.concat(y_train_list)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "feature_cols = X_train_combined.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [\n",
    "    c\n",
    "    for c in feature_cols\n",
    "    if c not in [\"registration\", \"ts_min\", \"ts_max\", \"total_length\"]\n",
    "]\n",
    "\n",
    "X_train_final = X_train_combined[feature_cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a06fa6-af99-49c7-aea4-016ea22e3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = aggregate_features_improved(df_test, \"2018-11-20\")\n",
    "X_test = test_features[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f171ee",
   "metadata": {},
   "source": [
    "We are trying to predict 0/1 Yes/No churn. The very first intuitive step to do is to apply Logistic Regression and then optimize it.\n",
    "\n",
    "Hence, we start by applying a vanilla Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48f7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base predicted churn: 49.86%\n",
      "Predicted churn at 0.5 threshold: 49.86%\n",
      "Submission saved to log_reg_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Documents\\X HEC\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(class_weight=\"balanced\")\n",
    "log_reg.fit(X_train_final, y_train_combined)\n",
    "\n",
    "evaluate_model(log_reg, X_test, 0.5, file_out=\"log_reg_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdcdcd",
   "metadata": {},
   "source": [
    "In Logistic Regression, we have hyperprameters that we need to choose *before* the training so we control how the model learns. Our hyperparameters are:\n",
    "\n",
    "- **C**: how much we penalize complexity (too high is overfitting, too low is underfitting)\n",
    "- **penalty**: which type of regularization we use (l1 or l2)\n",
    "- **solver**: which optimization algorithm we use\n",
    "\n",
    "Since we do not know which combination of these 3 is the best, we need to try all of them to decide which one we'll use in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2ac8e",
   "metadata": {},
   "source": [
    "For solver, we use \"Liblinear\", and \"Saga\". A solver is an optimization algorithm that finds the best model param during training. **Saga** is fast, uses low memory and is built for big data. Moreover, it uses Stochastic Average Gradient descent, meaning it updates the model parameters using small bacthes of data at time, it does not load the whole dataset in memory from the beginning, and it converges fast on big data. **Liblinear** is more reliable and is a classic choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d74dc8",
   "metadata": {},
   "source": [
    "**ROC-AUC** (area under the curve) measures how well the model separates the 2 classes, despite the imbalance. So in our case, it is used to answer:\n",
    "\n",
    "\"What is the probability the model will rank the churner higher if we pick one churner and one non-churner at random?\"\n",
    "\n",
    "Possible scores:\n",
    "\n",
    "- $<0.5$ means wrose than random\n",
    "- $~0.5$ means random guessing\n",
    "- $1.0$ means perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986a414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5274e352",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d0e0546",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036306a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model, X_test, 0.5, file_out=\"log_reg_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
