{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be21dc6b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91707aa2",
   "metadata": {},
   "source": [
    "In this notebook, we apply Logistic Regression to our data and we try to predict 'churn'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8dcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports will be here:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import import_and_transform\n",
    "from utils import evaluate_model\n",
    "from utils import aggregate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eee076",
   "metadata": {},
   "source": [
    "Based on the exploratory data analysis **EDA**, we will now modify our database accordingly. The EDA showed issues and necessary changed that require database modifications.\n",
    "\n",
    "We restructurate our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95583d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing data import and basic preprocessing:\n",
    "\n",
    "\n",
    "def import_and_transform(data):\n",
    "\n",
    "    if isinstance(data, str):\n",
    "        df = pd.read_parquet(data)\n",
    "    else:\n",
    "        df = data\n",
    "\n",
    "    # Remove invalid userIds and convert valid ones to integers\n",
    "    df = df[df[\"userId\"] != \"\"]\n",
    "    df[\"userId\"] = df[\"userId\"].astype(int)\n",
    "\n",
    "    # Ecnode the catgeorical variables\n",
    "    df[\"gender\"] = df[\"gender\"].map({\"F\": 0, \"M\": 1})\n",
    "    df[\"level\"] = df[\"level\"].map({\"free\": 0, \"paid\": 1})\n",
    "\n",
    "    # Convert the timestamps\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"], unit=\"ms\")\n",
    "    df[\"registration\"] = pd.to_datetime(df[\"registration\"])\n",
    "\n",
    "    # For each user session, we compute the duration in seconds\n",
    "    df[\"session_length\"] = df.groupby([\"userId\", \"sessionId\"])[\"ts\"].transform(\n",
    "        lambda x: (x.max() - x.min()).total_seconds()\n",
    "    )\n",
    "\n",
    "    # Song play indicator:\n",
    "    df[\"song_played\"] = (df[\"page\"] == \"NextSong\").astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7545b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating event-level data into user lvl features:\n",
    "\n",
    "\n",
    "def aggregate_features(data, observation_end):\n",
    "\n",
    "    observation_end = pd.Timestamp(observation_end)\n",
    "\n",
    "    # Aggregate features at user level:\n",
    "    user_df = (\n",
    "        data.groupby(\"userId\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"gender\": \"first\",\n",
    "                \"registration\": \"first\",\n",
    "                \"level\": lambda x: x.mode().iloc[0] if not x.mode().empty else 0,\n",
    "                \"sessionId\": \"nunique\",\n",
    "                \"itemInSession\": \"max\",\n",
    "                \"ts\": [\"min\", \"max\"],\n",
    "                \"session_length\": \"mean\",\n",
    "                \"song_played\": \"sum\",\n",
    "                \"artist\": pd.Series.nunique,\n",
    "                \"length\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # A more intuitive column order and names:\n",
    "    user_df.columns = [\n",
    "        \"userId\",\n",
    "        \"gender\",\n",
    "        \"registration\",\n",
    "        \"level\",\n",
    "        \"num_sessions\",\n",
    "        \"max_item_in_session\",\n",
    "        \"ts_min\",\n",
    "        \"ts_max\",\n",
    "        \"avg_session_length_seconds\",\n",
    "        \"num_songs_played\",\n",
    "        \"unique_artists\",\n",
    "        \"total_length\",\n",
    "    ]\n",
    "\n",
    "    # Creating time based engagement metrics:\n",
    "\n",
    "    # Days from the first activity to the end of the obs period\n",
    "    user_df[\"days_active\"] = (observation_end - user_df[\"ts_min\"]).dt.days\n",
    "\n",
    "    # Total membership duration\n",
    "    user_df[\"membership_length\"] = (observation_end - user_df[\"registration\"]).dt.days\n",
    "\n",
    "    # Engagement rates:\n",
    "    user_df[\"days_since_last_activity\"] = (observation_end - user_df[\"ts_max\"]).dt.days\n",
    "    user_df[\"songs_per_day\"] = user_df[\"num_songs_played\"] / (\n",
    "        user_df[\"days_active\"] + 1\n",
    "    )\n",
    "    user_df[\"sessions_per_day\"] = user_df[\"num_sessions\"] / (user_df[\"days_active\"] + 1)\n",
    "\n",
    "    # Fill missing values with 0s\n",
    "    user_df = user_df.fillna(0)\n",
    "\n",
    "    # Set userId as index\n",
    "    user_df.set_index(\"userId\", inplace=True)\n",
    "\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b204f2",
   "metadata": {},
   "source": [
    "Since in this competitions task we are asked to focus on the churn in a specific time window, we create a function which identifies who churned within a specified period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8b925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_churned_users(df, start_date, end_date):\n",
    "\n",
    "    # Convert the given dates to timestamps\n",
    "    start = pd.Timestamp(start_date)\n",
    "    end = pd.Timestamp(end_date)\n",
    "\n",
    "    # Identify users who cancelled their subscirptions in the given period\n",
    "    cancellations = df[df[\"page\"] == \"Cancellation Confirmation\"]\n",
    "    churned = cancellations[\n",
    "        (cancellations[\"ts\"] > start) & (cancellations[\"ts\"] <= end)\n",
    "    ][\"userId\"].unique()\n",
    "\n",
    "    # Return as a set\n",
    "    return set(churned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c4a47",
   "metadata": {},
   "source": [
    "Now, we are ready to load the train and test data and apply these modifications directly on our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbcd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = import_and_transform(\"Data/train.parquet\")\n",
    "\n",
    "# Prepare test data\n",
    "df_test = import_and_transform(\"Data/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab4245",
   "metadata": {},
   "source": [
    "We want to capture more temporal patterns. We want to \"teach\" the model to recognize churn patterns across different time periods. How do we do that?\n",
    "\n",
    "If we look at only one point in the time, we do not have enough examples to train the model. So instead of taking just one \"snapshot\", we take multiple snapshots at different times and we consider each one of them as individual prediction problems. \n",
    "\n",
    "Like this, we increase our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9f1716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date of the observation: 2018-10-15, with 16271 users, and a 5.08% churn rate\n",
      "Date of the observation: 2018-10-20, with 17347 users, and a 4.48% churn rate\n",
      "Date of the observation: 2018-10-25, with 17888 users, and a 4.49% churn rate\n",
      "Date of the observation: 2018-10-30, with 18271 users, and a 4.46% churn rate\n",
      "Date of the observation: 2018-11-04, with 18592 users, and a 3.78% churn rate\n"
     ]
    }
   ],
   "source": [
    "# Createing observation dates every 5 days\n",
    "# Create multiple training samples with sliding window\n",
    "training_dates = pd.date_range(\"2018-10-15\", \"2018-11-05\", freq=\"5D\")\n",
    "\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "# For each observ date, we create a separate training sample:\n",
    "for obs_date in training_dates:\n",
    "\n",
    "    # Filtering data up to the observation date\n",
    "    df_obs = df_train[df_train[\"ts\"] <= obs_date]\n",
    "    features = aggregate_features(df_obs, obs_date)\n",
    "\n",
    "    # Creating a 10 day window after the obervation date\n",
    "    # And we identify who churned in that period\n",
    "    window_end = obs_date + pd.Timedelta(days=10)\n",
    "    churned_users = get_churned_users(df_train, obs_date, window_end)\n",
    "\n",
    "    # 1 if they churned in the next 10 days, 0 otherwise\n",
    "    labels = pd.Series(\n",
    "        features.index.isin(churned_users).astype(int),\n",
    "        index=features.index,\n",
    "        name=\"churned\",\n",
    "    )\n",
    "\n",
    "    X_train_list.append(features)\n",
    "    y_train_list.append(labels)\n",
    "\n",
    "    print(\n",
    "        f\"Date of the observation: {obs_date.date()}, with {len(features)} users, and a {labels.mean():.2%} churn rate\"\n",
    "    )\n",
    "\n",
    "# We combine all observation windows:\n",
    "X_train_combined = pd.concat(X_train_list)\n",
    "y_train_combined = pd.concat(y_train_list)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "feature_cols = X_train_combined.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [\n",
    "    c\n",
    "    for c in feature_cols\n",
    "    if c not in [\"registration\", \"ts_min\", \"ts_max\", \"total_length\"]\n",
    "]\n",
    "\n",
    "X_train_final = X_train_combined[feature_cols]\n",
    "\n",
    "test_features = aggregate_features(df_test, \"2018-11-20\")\n",
    "X_test = test_features[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f171ee",
   "metadata": {},
   "source": [
    "We are trying to predict 0/1 Yes/No churn. The very first intuitive step to do is to apply Logistic Regression and then optimize it.\n",
    "\n",
    "Hence, we start by applying a vanilla Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48f7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base predicted churn: 31.96%\n",
      "Predicted churn at 0.5 threshold: 31.96%\n",
      "Submission saved to log_reg_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "log_reg.fit(X_train_final, y_train_combined)\n",
    "\n",
    "from utils import evaluate_model\n",
    "\n",
    "evaluate_model(log_reg, X_test, 0.5, file_out=\"log_reg_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdcdcd",
   "metadata": {},
   "source": [
    "In Logistic Regression, we have hyperprameters that we need to choose *before* the training so we control how the model learns. Our hyperparameters are:\n",
    "\n",
    "- **C**: how much we penalize complexity (too high is overfitting, too low is underfitting)\n",
    "- **penalty**: which type of regularization we use (l1 or l2)\n",
    "- **solver**: which optimization algorithm we use\n",
    "\n",
    "Since we do not know which combination of these 3 is the best, we need to try all of them to decide which one we'll use in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2ac8e",
   "metadata": {},
   "source": [
    "For solver, we use \"Liblinear\", and \"Saga\". A solver is an optimization algorithm that finds the best model param during training. **Saga** is fast, uses low memory and is built for big data. Moreover, it uses Stochastic Average Gradient descent, meaning it updates the model parameters using small bacthes of data at time, it does not load the whole dataset in memory from the beginning, and it converges fast on big data. **Liblinear** is more reliable and is a classic choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d74dc8",
   "metadata": {},
   "source": [
    "**ROC-AUC** (area under the curve) measures how well the model separates the 2 classes, despite the imbalance. So in our case, it is used to answer:\n",
    "\n",
    "\"What is the probability the model will rank the churner higher if we pick one churner and one non-churner at random?\"\n",
    "\n",
    "Possible scores:\n",
    "\n",
    "- $<0.5$ means wrose than random\n",
    "- $~0.5$ means random guessing\n",
    "- $1.0$ means perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4986a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "Best parameters: {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best CV ROC-AUC: 0.7017\n"
     ]
    }
   ],
   "source": [
    "# We define the param grid\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 1, 5, 50], # Regularization strength\n",
    "    \"penalty\": [\"l1\", \"l2\"], # l1 = Lasso, l2 = Ridge\n",
    "    \"solver\": [\"liblinear\", \"saga\"], # Optim algorithm\n",
    "    \"class_weight\": [\"balanced\"], # Handle class imbalance\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "\n",
    "# We use cross-validation, because our dataset is imbalanced\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# We perform grid search over all the combinations\n",
    "# We optimize for ROC-AUC\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# We train on all the combinations of parameters\n",
    "grid_search.fit(X_train_final, y_train_combined)\n",
    "\n",
    "print()\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Let's save the best model now:\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274e352",
   "metadata": {},
   "source": [
    "We found the best parameters and we will use them to evaluate on the test set.\n",
    "\n",
    "We got the best ROC-AUC score of 70%, which means that the model learned some real churn patters. However, 30% will miss some churners. The ideal ROC-AUC score for churn prediction should be around 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e0546",
   "metadata": {},
   "source": [
    "Now that we have the best model, let's evaluate it on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "036306a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base predicted churn: 61.78%\n",
      "Predicted churn at 0.5 threshold: 61.78%\n",
      "Submission saved to log_reg_2.csv\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(best_model, X_test, 0.5, file_out=\"log_reg_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88416fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
